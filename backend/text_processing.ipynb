{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import spacy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>outlet</th>\n",
       "      <th>bias</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.bbc.com/arabic/articles/c4g3rqvpnq...</td>\n",
       "      <td>Trump signs order to impose tariffs on goods i...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>center</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>صدر الصورة، Getty Images أعلنت كندا فرض رسوم ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.thehindu.com/news/international/tr...</td>\n",
       "      <td>Trump signs executive order to impose tariffs ...</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>leanLeft</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>February 2, 2025e-Paper \\n\\t\\t\\t\\t\\t\\t\\t\\t\\tTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.news18.com/world/us-imposes-tariff...</td>\n",
       "      <td>Canada Imposes 25% Tariffs Against US; Mexico,...</td>\n",
       "      <td>News18 India</td>\n",
       "      <td>leanRight</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>Canada imposed 25 per cent tariffs on $155 bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://apnews.com/article/trump-tariffs-mexic...</td>\n",
       "      <td>What do Trump's executive orders say on tariff...</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>leanLeft</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>Copyright 2025 The Associated Press. All Right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ndtv.com/world-news/donald-trump-i...</td>\n",
       "      <td>Explained: What Are Tariffs Imposed By Donald ...</td>\n",
       "      <td>NDTV</td>\n",
       "      <td>leanRight</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>US President Donald Trump signed an order impo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.bbc.com/arabic/articles/c4g3rqvpnq...   \n",
       "1  https://www.thehindu.com/news/international/tr...   \n",
       "2  https://www.news18.com/world/us-imposes-tariff...   \n",
       "3  https://apnews.com/article/trump-tariffs-mexic...   \n",
       "4  https://www.ndtv.com/world-news/donald-trump-i...   \n",
       "\n",
       "                                               title                 outlet  \\\n",
       "0  Trump signs order to impose tariffs on goods i...               BBC News   \n",
       "1  Trump signs executive order to impose tariffs ...              The Hindu   \n",
       "2  Canada Imposes 25% Tariffs Against US; Mexico,...           News18 India   \n",
       "3  What do Trump's executive orders say on tariff...  Associated Press News   \n",
       "4  Explained: What Are Tariffs Imposed By Donald ...                   NDTV   \n",
       "\n",
       "        bias        date                                            content  \n",
       "0     center  2025-02-01  صدر الصورة، Getty Images أعلنت كندا فرض رسوم ج...  \n",
       "1   leanLeft  2025-02-01  February 2, 2025e-Paper \\n\\t\\t\\t\\t\\t\\t\\t\\t\\tTh...  \n",
       "2  leanRight  2025-02-01  Canada imposed 25 per cent tariffs on $155 bil...  \n",
       "3   leanLeft  2025-02-01  Copyright 2025 The Associated Press. All Right...  \n",
       "4  leanRight  2025-02-01  US President Donald Trump signed an order impo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df = pd.read_csv('data/complete_article_data.csv')\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>outlet</th>\n",
       "      <th>bias</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.bbc.com/arabic/articles/c4g3rqvpnq...</td>\n",
       "      <td>Trump signs order to impose tariffs on goods i...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>center</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>صدر الصورة، Getty Images أعلنت كندا فرض رسوم ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.thehindu.com/news/international/tr...</td>\n",
       "      <td>Trump signs executive order to impose tariffs ...</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>leanLeft</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>February 2, 2025e-Paper \\n\\t\\t\\t\\t\\t\\t\\t\\t\\tTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.news18.com/world/us-imposes-tariff...</td>\n",
       "      <td>Canada Imposes 25% Tariffs Against US; Mexico,...</td>\n",
       "      <td>News18 India</td>\n",
       "      <td>leanRight</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>Canada imposed 25 per cent tariffs on $155 bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://apnews.com/article/trump-tariffs-mexic...</td>\n",
       "      <td>What do Trump's executive orders say on tariff...</td>\n",
       "      <td>Associated Press News</td>\n",
       "      <td>leanLeft</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>Copyright 2025 The Associated Press. All Right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.ndtv.com/world-news/donald-trump-i...</td>\n",
       "      <td>Explained: What Are Tariffs Imposed By Donald ...</td>\n",
       "      <td>NDTV</td>\n",
       "      <td>leanRight</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>US President Donald Trump signed an order impo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.bbc.com/arabic/articles/c4g3rqvpnq...   \n",
       "1  https://www.thehindu.com/news/international/tr...   \n",
       "2  https://www.news18.com/world/us-imposes-tariff...   \n",
       "3  https://apnews.com/article/trump-tariffs-mexic...   \n",
       "4  https://www.ndtv.com/world-news/donald-trump-i...   \n",
       "\n",
       "                                               title                 outlet  \\\n",
       "0  Trump signs order to impose tariffs on goods i...               BBC News   \n",
       "1  Trump signs executive order to impose tariffs ...              The Hindu   \n",
       "2  Canada Imposes 25% Tariffs Against US; Mexico,...           News18 India   \n",
       "3  What do Trump's executive orders say on tariff...  Associated Press News   \n",
       "4  Explained: What Are Tariffs Imposed By Donald ...                   NDTV   \n",
       "\n",
       "        bias        date                                            content  \n",
       "0     center  2025-02-01  صدر الصورة، Getty Images أعلنت كندا فرض رسوم ج...  \n",
       "1   leanLeft  2025-02-01  February 2, 2025e-Paper \\n\\t\\t\\t\\t\\t\\t\\t\\t\\tTh...  \n",
       "2  leanRight  2025-02-01  Canada imposed 25 per cent tariffs on $155 bil...  \n",
       "3   leanLeft  2025-02-01  Copyright 2025 The Associated Press. All Right...  \n",
       "4  leanRight  2025-02-01  US President Donald Trump signed an order impo...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_df['content'].values[1].strip()\n",
    "article_df['content'] = article_df['content'].apply(lambda x: x.strip())\n",
    "\n",
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_txt = article_df['content'][1]\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_text(title: str, text: str):\n",
    "    nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "    nlp2 = spacy.load(\"en_core_web_sm\")\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove excess blank lines\n",
    "    text = re.sub(r'\\t\\s*\\t', '\\t', text)\n",
    "    text = text.encode(\"utf-8\", errors='ignore').decode(\"utf-8\") #Replacing unicode characters\n",
    "    text = text.strip()\n",
    "    doc: spacy.tokens.doc.Doc = nlp1(text)\n",
    "    title = nlp2(title)\n",
    "    first_subject = False\n",
    "    relevant_lines = []\n",
    "    article_flags = []\n",
    "\n",
    "    #Making a list of relevant subjects/nouns in the title\n",
    "    for word in title:\n",
    "        if word.pos_ == 'PROPN':\n",
    "            article_flags.append(word)\n",
    "        elif word.dep_ in ['nsubj', 'ROOT']:\n",
    "            article_flags.append(word)\n",
    "        elif word.ent_id_ in ['PERSON', 'ORG', 'GPE']:\n",
    "            article_flags.append(word)\n",
    "    article_flags = [str(x).lower() for x in article_flags]\n",
    "\n",
    "    #Keeping all sentences after first appearance of relevant word\n",
    "    doc_sents = [x for x in doc.sents]\n",
    "    #print(doc_sents)\n",
    "    doc_reverse = list(reversed(doc_sents))\n",
    "    for sentence in doc_sents:\n",
    "        if not first_subject:\n",
    "            for word in sentence:\n",
    "                word = str(word).lower()\n",
    "                if word in article_flags:\n",
    "                    first_subject = True\n",
    "                    relevant_lines.append(str(sentence))\n",
    "        else:\n",
    "            relevant_lines.append(str(sentence))\n",
    "    \n",
    "    #Removing all ending text after the last mention of a relevant entity\n",
    "    last_subject=False\n",
    "    for ind, sentence in enumerate(doc_reverse):\n",
    "        if not last_subject:\n",
    "            for word in sentence:\n",
    "                word = str(word).lower()\n",
    "                if word in article_flags:\n",
    "                    last_subject = True\n",
    "                    last_subj_ind = ind\n",
    "\n",
    "    relevant_lines = relevant_lines[:-last_subj_ind]\n",
    "    seen_lines = []\n",
    "    for sentence in relevant_lines:\n",
    "        if sentence in seen_lines:\n",
    "            continue\n",
    "        seen_lines.append(sentence.strip())\n",
    "    #print(seen_lines, relevant_lines)\n",
    "\n",
    "    return ' '.join(seen_lines)\n",
    "\n",
    "\n",
    "def filter_text_2(text: str, nlp):\n",
    "    text = re.sub(r'\\n\\s*\\n', '\\n', text)  # Remove excess blank lines\n",
    "    text = re.sub(r'\\t\\s*\\t', '\\t', text)\n",
    "    text = text.encode(\"utf-8\", errors='ignore').decode(\"utf-8\") #Replacing unicode characters\n",
    "    text = text.strip()\n",
    "    doc: spacy.tokens.doc.Doc = nlp(text)\n",
    "    first_subject = False\n",
    "    relevant_lines = []\n",
    "    article_flags = {}\n",
    "    doc_sents = [x for x in doc.sents]\n",
    "\n",
    "    #Making a list of relevant subjects/nouns in the title\n",
    "    for sent in doc_sents:\n",
    "        for word in sent:\n",
    "            w_str = str(word).lower()\n",
    "            if word.pos_ == 'PROPN':\n",
    "                if w_str not in article_flags:\n",
    "                    article_flags[w_str] = 0\n",
    "                article_flags[w_str] += 1\n",
    "            elif word.dep_ in ['nsubj', 'ROOT']:\n",
    "                if w_str not in article_flags:\n",
    "                    article_flags[w_str] = 0\n",
    "                article_flags[w_str] += 1\n",
    "            elif word.ent_id_ in ['PERSON', 'ORG', 'GPE']:\n",
    "                if w_str not in article_flags:\n",
    "                    article_flags[w_str] = 0\n",
    "                article_flags[w_str] += 1\n",
    "    common_flag_vals = sorted(list(article_flags.values()), reverse=True)[:3]\n",
    "    common_flags = [x for x,y in article_flags.items() if y in common_flag_vals]\n",
    "    print(common_flags)\n",
    "    #Keeping all sentences after first appearance of relevant word\n",
    "    #print(doc_sents)\n",
    "    doc_reverse = list(reversed(doc_sents))\n",
    "    for sentence in doc_sents:\n",
    "        if not first_subject:\n",
    "            for word in sentence:\n",
    "                word = str(word).lower()\n",
    "                if word in common_flags:\n",
    "                    first_subject = True\n",
    "                    relevant_lines.append(str(sentence))\n",
    "        else:\n",
    "            relevant_lines.append(str(sentence))\n",
    "    \n",
    "    #Removing all ending text after the last mention of a relevant entity\n",
    "    last_subject=False\n",
    "    for ind, sentence in enumerate(doc_reverse):\n",
    "        if not last_subject:\n",
    "            for word in sentence:\n",
    "                word = str(word).lower()\n",
    "                if word in common_flags:\n",
    "                    last_subject = True\n",
    "                    last_subj_ind = ind\n",
    "\n",
    "    relevant_lines = relevant_lines[:-last_subj_ind]\n",
    "    seen_lines = []\n",
    "    for sentence in relevant_lines:\n",
    "        if sentence in seen_lines:\n",
    "            continue\n",
    "        seen_lines.append(sentence.strip())\n",
    "    full_text = ' '.join(seen_lines)\n",
    "    return full_text\n",
    "\n",
    "    #Further processing \n",
    "    pattern = r\"\\n\"\n",
    "    full_text = re.sub(pattern, \".\", full_text)\n",
    "    pattern2 = r'\\s{2,}'\n",
    "    full_text = re.sub(pattern2, \"\", full_text)\n",
    "\n",
    "    #removing sentences that have between 2 and 4 words\n",
    "    sents = full_text.split(\".\")\n",
    "    sents_cleaned = [x for x in sents if not 4 >= len(x.split()) >1]    \n",
    "\n",
    "    return \n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/105.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "}\n",
    "\n",
    "proxy_list = []\n",
    "with open(\"proxies.txt\", \"r\") as f:\n",
    "    proxies = f.read().split('\\n')\n",
    "    for prox in proxies:\n",
    "        proxy_list.append(prox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "['said', 'trump', 'president', 'u.s.', 'we']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_url(url, headers, proxy):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=2.5, headers=headers)\n",
    "        print(response.status_code)\n",
    "        if response.status_code != 200:\n",
    "            url = f\"https://web.archive.org/web/{url}\"\n",
    "            response = requests.get(url, timeout=2.5, headers=headers, proxies=proxies)\n",
    "            if response.status_code != 200:\n",
    "                print('error')\n",
    "                return 'Error'\n",
    "    except:\n",
    "        return 'Error'\n",
    "    content = BeautifulSoup(response.text, \"html.parser\")\n",
    "    all_p = content.find_all('p')\n",
    "    clean_text = [x.text for x in all_p]\n",
    "    full_text = ' '.join(clean_text)\n",
    "    return full_text\n",
    "\n",
    "url = 'https://www.theepochtimes.com/us/white-house-official-says-more-than-15-countries-have-made-trade-deal-offers-5839767'\n",
    "pattern = r\"\\s\"\n",
    "url = re.sub(pattern, \"\", url)\n",
    "url_text = scrape_url(url, headers, proxy=proxy_list[25])\n",
    "filter_text_2(url_text, nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_proxies():\n",
    "    proxy_list = []\n",
    "    working_proxies = []\n",
    "    with open(\"proxies_unfiltered.txt\", \"r\") as f:\n",
    "        proxies = f.read().split('\\n')\n",
    "        for prox in proxies:\n",
    "            proxy_list.append(prox)\n",
    "\n",
    "    for proxy in proxy_list:\n",
    "        proxy_dict = {\"http\": proxy, \"https\": proxy}\n",
    "        try:\n",
    "            resp = requests.get(url, headers=headers, proxies=proxy_dict, timeout=2.5).status_code\n",
    "        except:\n",
    "            continue\n",
    "        if resp == 200:\n",
    "            print(proxy)\n",
    "            working_proxies.append(proxy)\n",
    "    return working_proxies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://www.bloomberg.com/news/articles/2025-04-10/hassett-says-us-well-advanced-in-trade-talks-with-some-nations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    previous_article_df = pd.read_csv('data/Clean_article_text.csv')\n",
    "    seen_urls = previous_article_df['url'].values\n",
    "except:\n",
    "    seen_urls = []\n",
    "\n",
    "cleaned_content = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(article_df.shape[0]):\n",
    "    row = article_df.iloc[i]\n",
    "    content = row['content']\n",
    "    title = row['title']\n",
    "    #print(title, content)\n",
    "    url = row['url']\n",
    "    if url not in seen_urls:\n",
    "        try:\n",
    "            cleaned_text = filter_text(title, content)\n",
    "            if cleaned_text:\n",
    "                cleaned_content.append(cleaned_text)\n",
    "            else:\n",
    "                cleaned_content.append('Error')\n",
    "        except:\n",
    "            cleaned_content.append('Error')\n",
    "        seen_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cflor\\AppData\\Local\\Temp\\ipykernel_26940\\1227318586.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  article_unique['cleaned_text'] = cleaned_content\n",
      "C:\\Users\\cflor\\AppData\\Local\\Temp\\ipykernel_26940\\1227318586.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  article_unique['word_count'] = article_unique['cleaned_text'].apply(lambda x: len(x.split()))\n"
     ]
    }
   ],
   "source": [
    "urls = article_df['url'].values.tolist()\n",
    "article_unique = article_df.drop_duplicates(subset=['url'],keep='first')\n",
    "article_unique['cleaned_text'] = cleaned_content\n",
    "article_unique['word_count'] = article_unique['cleaned_text'].apply(lambda x: len(x.split()))\n",
    "clean_text_df = article_unique.loc[article_unique['word_count'] > 10]\n",
    "clean_text_df.to_csv('data/Clean_article_text.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
